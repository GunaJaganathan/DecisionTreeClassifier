{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dR3AAcMWUwVv"
      },
      "source": [
        "# Decision Tree Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "kCMNjsth-0Wg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "import sklearn.metrics as metrics\n",
        "import random\n",
        "from sklearn.model_selection import KFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "W0mMKnNK-ur2"
      },
      "outputs": [],
      "source": [
        "def read_input_file(inputFile: str, features : list = None, column_names: bool = None):\n",
        "  '''Function to read input csv files.\n",
        "  Parameters\n",
        "  ----------\n",
        "  inputFile : str\n",
        "    Input file name or path\n",
        "  features : list, default = None\n",
        "    list of features present in the given input file\n",
        "  column_names : {True, False}, default = None\n",
        "    if set to False the first row of the input file will be considered as features else the given feature list will be added as column names\n",
        "  \n",
        "  Return\n",
        "  ------\n",
        "  input_dataframe : pd.DataFrame\n",
        "    returns input data as dataframe\n",
        "    '''\n",
        "  if column_names == True:\n",
        "    input_dataframe = pd.read_csv(inputFile,names=features, index_col=None)\n",
        "  elif column_names == False or column_names == None:\n",
        "    input_dataframe = pd.read_csv(inputFile)\n",
        "  return input_dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Map the features of input dataset by reading the feature mapping file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reads\n",
        "features = read_input_file(f'../Data/featuremapping.csv', features= None, column_names=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_mapping = {}\n",
        "features_list = list(features['Features'])\n",
        "feature_mapping['continuous'] = list(features[(features['Type'] == 'continuous')]['Features'])\n",
        "feature_mapping['discrete'] = list(features[(features['Type'] == 'discrete')]['Features'])\n",
        "feature_mapping['missing'] = list(features[(features['Missing Values'] == 'yes')]['Features'])\n",
        "feature_mapping['target_column'] = list(features[(features['Target'] == 'Yes')]['Features'])\n",
        "if len(feature_mapping['target_column']) >1:\n",
        "    print(f'Target cannot be more than one column. The provided feature making has {len(feature_mapping[\"target\"])} target value')\n",
        "else:\n",
        "    feature_mapping['target'] = feature_mapping['target_column'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Read the credit approval train and test dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "1Pj8h8MMUphM"
      },
      "outputs": [],
      "source": [
        "train_data = read_input_file(f'../Data/training.data', features= features_list, column_names=True)\n",
        "test_data = read_input_file(f'../Data/test.data', features= features_list, column_names=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Class for data preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "8dE033lchXBm"
      },
      "outputs": [],
      "source": [
        "class preprocessing:\n",
        "  def fill_nan(self, train_data, test_data):\n",
        "    '''Function to replace the '?' in dataset with median value\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    train_data : pd.DataFrame\n",
        "      Dataset for training the model\n",
        "    test_data : pd.DataFrame\n",
        "      Dataset for testing the model\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    train_data : pd.DataFrame\n",
        "      Training dataset without '?'. '?' replaced with median calculaed from training dataset\n",
        "    test_data : pd.DataFrame\n",
        "      Testing dataset without '?'. '?' replaced with median calculaed from training dataset\n",
        "    '''\n",
        "    for cols in train_data.columns:\n",
        "      if cols in feature_mapping[\"continuous\"]:\n",
        "        train_data_without_q = train_data.drop(train_data[train_data[cols] == \"?\"].index)\n",
        "        median = train_data_without_q[cols].median()\n",
        "        train_data[cols].replace(\"?\",median, inplace=True)\n",
        "        test_data[cols].replace(\"?\",median, inplace=True)\n",
        "        if not isinstance(train_data[cols].dtype,np.int64):\n",
        "          train_data[cols] = [float(val) for val in train_data[cols]]\n",
        "          test_data[cols] = [float(val) for val in test_data[cols]]\n",
        "      elif cols in feature_mapping[\"discrete\"] and cols != \"A16\":\n",
        "        train_data_without_q = train_data.drop(train_data[train_data[cols] == \"?\"].index)\n",
        "        unique_values = train_data_without_q[cols].unique()\n",
        "        unique_values.sort()\n",
        "        index = math.ceil((len(unique_values)+1)/2)\n",
        "        train_data[cols].replace(\"?\",unique_values[index-1], inplace=True)\n",
        "        test_data[cols].replace(\"?\",unique_values[index-1], inplace=True)\n",
        "    return train_data, test_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVF8kERrNqap",
        "outputId": "488609cb-2ec2-4fb5-c570-70e099056ab7"
      },
      "outputs": [],
      "source": [
        "#Object is created for preprocessing class and fill_nan function is invoked\n",
        "preObj = preprocessing()\n",
        "train_data, test_data = preObj.fill_nan(train_data, test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Class for decision tree helper functions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "ZxTAtLfxurJg"
      },
      "outputs": [],
      "source": [
        "class decisionTreeHelper:\n",
        "  def __init__(self, criterion : str = 'C4.5'):\n",
        "        self.__gain = {}\n",
        "        self.__gainratio = {}\n",
        "        self.__giniindex = {}\n",
        "        self.__criterion = criterion\n",
        "        self.data = None\n",
        "\n",
        "  def merge_data_label(self, data: pd.DataFrame, class_label: pd.DataFrame):\n",
        "    '''Function to merge the dataset features with class label.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "      All feature columns in the dataset except class label.\n",
        "    class_label : pd.DataFrame\n",
        "      Class label column in the dataset.\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    data : pd.DataFrame\n",
        "      Feature columns merged with class_lable column.\n",
        "    '''\n",
        "    self.data = data\n",
        "    self.data.insert(len(data.columns),\"label\",list(class_label.values),True)\n",
        "    return data\n",
        "\n",
        "  def __calculate_entropy(self,data : pd.DataFrame):\n",
        "    '''Function to calculate entropy.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "      Input dataset as pd.DataFrame to calculate entropy.\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    entropy : float\n",
        "      Entropy value of given dataset\n",
        "    '''\n",
        "    entropy = 0.0\n",
        "    filtereddata = data\n",
        "    groupedbylabel = data.groupby('label')\n",
        "    for dataKey, dataGroup in groupedbylabel:\n",
        "      precentage = len(dataGroup)/len(filtereddata)\n",
        "      entropy -= precentage * math.log2(precentage)\n",
        "    return entropy\n",
        "\n",
        "  def __best_con_feature_split(self, data : pd.DataFrame, feature_name : list):\n",
        "    '''Function to find the best split for continous features.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "      Input dataset as pd.DataFrame to calculate entropy.\n",
        "    feature_name : list\n",
        "      List of feature names.\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    best_gain_split_value : float\n",
        "      Best split value based on information gain(ID3)\n",
        "    best_gain_ratio_split_value : float\n",
        "      Best split value based on gain ratio(C4.5)\n",
        "    best_gini_split_value : float\n",
        "      Best split value based on gini index(CART)\n",
        "      \n",
        "    '''\n",
        "    con_value_split_lists = []\n",
        "    gain = {}\n",
        "    gainratio = {}\n",
        "    giniindex = {}\n",
        "    best_gain_split_value = None\n",
        "    best_gain_ratio_split_value = None\n",
        "    best_gini_split_value = None\n",
        "    feature_entropy = 0.0\n",
        "    feature_intrinsic_value = 0.0\n",
        "    total_entropy = self.__calculate_entropy(data)\n",
        "    \n",
        "    for index in range(len(data[feature_name])-1):\n",
        "      con_value = list(data[feature_name])\n",
        "      con_value.sort()\n",
        "      con_value_lists = list(con_value)\n",
        "      con_value_split_lists.append((con_value_lists[index]+con_value_lists[index+1])/2)\n",
        "    con_value_split_lists = set(con_value_split_lists)\n",
        "    \n",
        "    for i in con_value_split_lists:\n",
        "      if self.__criterion == 'ID3' or self.__criterion == 'C4.5':\n",
        "        feature_value_precentage_less = len(data.query(f'{feature_name}<={i}')) / len(data)\n",
        "        feature_value_precentage_more = len(data.query(f'{feature_name}>{i}')) / len(data)\n",
        "        feature_value_entropy_less = self.__calculate_entropy(data.query(f'{feature_name}<={i}'))\n",
        "        feature_value_entropy_more = self.__calculate_entropy(data.query(f'{feature_name}>{i}'))\n",
        "        feature_entropy = (feature_value_precentage_less * feature_value_entropy_less) + (feature_value_precentage_more * feature_value_entropy_more)\n",
        "        if feature_value_precentage_less == 0:\n",
        "          feature_value_precentage_less = 1\n",
        "        if feature_value_precentage_more == 0:\n",
        "          feature_value_precentage_more = 1\n",
        "        feature_intrinsic_value = -((feature_value_precentage_less * math.log2(feature_value_precentage_less)) + (feature_value_precentage_more * math.log2(feature_value_precentage_more)))\n",
        "        gain[i] = total_entropy - feature_entropy\n",
        "        if feature_intrinsic_value != 0.0:\n",
        "          gainratio[i] = gain[i]/feature_intrinsic_value\n",
        "        else:\n",
        "          gainratio[i] = 0.0\n",
        "      if self.__criterion == 'CART':\n",
        "        feature_value_precentage_less = len(data.query(f'{feature_name}<={i}')) / len(data)\n",
        "        feature_value_precentage_more = len(data.query(f'{feature_name}>{i}')) / len(data)\n",
        "        feature_value_entropy_less = self.__calculate_gini(data.query(f'{feature_name}<={i}'))\n",
        "        feature_value_entropy_more = self.__calculate_gini(data.query(f'{feature_name}>{i}'))\n",
        "        giniindex[i] = (feature_value_precentage_less * feature_value_entropy_less) + (feature_value_precentage_more * feature_value_entropy_more)\n",
        "    \n",
        "    if self.__criterion == 'ID3' or self.__criterion == 'C4.5':\n",
        "      best_gain_split_value = max(gain, key=gain.get)\n",
        "      best_gain_ratio_split_value = max(gainratio, key=gainratio.get)\n",
        "      self.__gain[feature_name] = gain[best_gain_split_value]\n",
        "      self.__gainratio[feature_name] = gainratio[best_gain_ratio_split_value]\n",
        "    if self.__criterion == 'CART':\n",
        "      best_gini_split_value = min(giniindex, key=giniindex.get)\n",
        "      self.__giniindex[feature_name] = giniindex[best_gini_split_value]\n",
        "    \n",
        "    return best_gain_split_value, best_gain_ratio_split_value, best_gini_split_value\n",
        "\n",
        "  def __calculate_gain_ratio(self, data : pd.DataFrame):\n",
        "    '''Function to calculate gain and gain ratio.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "      Input dataset as pd.DataFrame to calculate entropy.\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    best_gain_split_value : dict\n",
        "      Dict of best split based on gain for all the  features in the  input data\n",
        "    best_gain_ratio_split_value : dict\n",
        "      Dict of best split based on gain ratio for all the  features in the  input data\n",
        "    self.__gain : \n",
        "      Dict of gain for all the  features in the  input data\n",
        "    self.__gainratio :\n",
        "      Dict of gain ratio for all the  features in the  input data\n",
        "    '''\n",
        "    self.__gainratio = {}\n",
        "    best_gain_split_value = {}\n",
        "    best_gain_ratio_split_value = {}\n",
        "    best_gini_split_value = {}\n",
        "    total_entropy = self.__calculate_entropy(data)\n",
        "    bestgainratio = 0.0\n",
        "    for featureIndex in range(len(data.columns)-1):\n",
        "      feature_name = data.columns[featureIndex]\n",
        "      if (feature_name in feature_mapping[\"continuous\"]):\n",
        "        best_gain_split_value[feature_name], best_gain_ratio_split_value[feature_name], best_gini_split_value[feature_name] = self.__best_con_feature_split(data,feature_name)\n",
        "      else:\n",
        "        feature_entropy = 0.0\n",
        "        feature_intrinsic_value = 0.0\n",
        "        groupedByFeature = data.groupby(feature_name)\n",
        "        for featureKey, featureValueGroup in groupedByFeature:\n",
        "          featureValueEntropy = self.__calculate_entropy(featureValueGroup)\n",
        "          featureValueprecentage = len(featureValueGroup) / len(data)\n",
        "          feature_entropy += featureValueprecentage * featureValueEntropy\n",
        "          feature_intrinsic_value -= featureValueprecentage * math.log2(featureValueprecentage)\n",
        "        self.__gain[feature_name] = total_entropy - feature_entropy\n",
        "        if feature_intrinsic_value != 0.0:\n",
        "          self.__gainratio[feature_name] = self.__gain[feature_name]/feature_intrinsic_value\n",
        "        else:\n",
        "          self.__gainratio[feature_name] = 0.0\n",
        "    return best_gain_split_value, best_gain_ratio_split_value, self.__gain, self.__gainratio\n",
        "\n",
        "  def __calculate_gini(self,data : pd.DataFrame):\n",
        "    '''Function to calculate gini.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "      Input dataset as pd.DataFrame to calculate gini.\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    gini : float\n",
        "      Gini value of given dataset\n",
        "    '''\n",
        "    gini = 0.0\n",
        "    groupedbylabel = data.groupby('label')\n",
        "    for dataKey, dataGroup in groupedbylabel:\n",
        "      precentage = len(dataGroup)/len(data)\n",
        "      gini += math.pow(precentage,2)\n",
        "    gini = 1 - gini\n",
        "    return gini\n",
        "\n",
        "  def __calculate_gini_index(self, data : pd.DataFrame):\n",
        "    '''Function to calculate gini index.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    data : pd.DataFrame\n",
        "      Input dataset as pd.DataFrame to calculate entropy.\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    best_gini_split_value : dict\n",
        "      Dict of best split based on gain for all the  features in the  input data\n",
        "    self.__giniindex :\n",
        "      Dict of gini index for all the  features in the  input data\n",
        "    '''\n",
        "    self.__giniindex = {}\n",
        "    best_gain_split_value = {}\n",
        "    best_gain_ratio_split_value = {}\n",
        "    best_gini_split_value = {}\n",
        "    for featureIndex in range(len(data.columns)-1):\n",
        "      feature_name = data.columns[featureIndex]\n",
        "      groupedByFeature = data.groupby(feature_name)\n",
        "      featureGini = 0.0\n",
        "      if (feature_name in feature_mapping[\"continuous\"]):\n",
        "        best_gain_split_value[feature_name], best_gain_ratio_split_value[feature_name], best_gini_split_value[feature_name] = self.__best_con_feature_split(data,feature_name)\n",
        "      else:\n",
        "        for featureKey, featureValueGroup in groupedByFeature:\n",
        "          featureValueGini = self.__calculate_gini(featureValueGroup)\n",
        "          featureValueprecentage = len(featureValueGroup) / len(data)\n",
        "          featureGini += featureValueprecentage * featureValueGini\n",
        "        self.__giniindex[feature_name] = featureGini\n",
        "    return best_gini_split_value, self.__giniindex\n",
        "\n",
        "  def get_best_feature(self, train_values : pd.DataFrame, feature_list : list):\n",
        "    '''Function to find the best feature based on input criterion(ID3, C4.5, CART).\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    train_values : pd.DataFrame\n",
        "      Input dataset as pd.DataFrame.\n",
        "    feature_list : pd.DataFrame\n",
        "      List of features in the input dataset.\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    best_gini_split_value : dict\n",
        "      Dict of best split based on gain for all the  features in the  input data\n",
        "    self.__giniindex :\n",
        "      Dict of gini index for all the  features in the  input data\n",
        "    '''\n",
        "    feature_list = list(feature_list)\n",
        "    feature_list.sort()\n",
        "    feature_list.remove('label')\n",
        "    if self.__criterion == 'C4.5':\n",
        "      gainratio = {}\n",
        "      _, best_split_value, _, _ = self.__calculate_gain_ratio(train_values)\n",
        "      for key in feature_list:\n",
        "          gainratio[key] = self.__gainratio[key]\n",
        "      best_feature = max(gainratio, key=gainratio.get)\n",
        "    elif self.__criterion == 'CART':\n",
        "      giniindex = {}\n",
        "      best_split_value, _ = self.__calculate_gini_index(train_values)\n",
        "      for key in feature_list:\n",
        "          giniindex[key] = self.__giniindex[key]\n",
        "      best_feature = min(giniindex, key=giniindex.get)\n",
        "    elif self.__criterion == 'ID3':\n",
        "      gain = {}\n",
        "      best_split_value, _, _, _ = self.__calculate_gain_ratio(train_values)\n",
        "      for key in feature_list:\n",
        "          gain[key] = self.__gain[key]\n",
        "      best_feature = max(gain, key=gain.get)\n",
        "    else:\n",
        "      print(f'Provide valid value(Either ID3, C4.5 or CART) for criterion. {self.__criterion} is invalid')\n",
        "    return best_split_value, best_feature\n",
        "  \n",
        "  def get_performance_score(self, actual_label : list, predicted_label : list):\n",
        "    '''Function to calculate the performance metric using sklearn.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    actual_label : list\n",
        "      Actual(Ground Truth) class label from the dataset.\n",
        "    predicted_label : pd.DataFrame\n",
        "      Class label predicted by the model\n",
        "    \n",
        "    Return\n",
        "    ------\n",
        "    f1_score : float\n",
        "    accuracy : float\n",
        "    precision : float\n",
        "    recall : float\n",
        "    AUROC : float\n",
        "    '''\n",
        "    actual_label = actual_label.replace('+',1)\n",
        "    actual_label = actual_label.replace('-',0)\n",
        "    predicted_label = pd.DataFrame(predicted_label).replace('+',1)\n",
        "    predicted_label = pd.DataFrame(predicted_label).replace('-',0)\n",
        "    precision = metrics.precision_score(actual_label, predicted_label, pos_label=1)\n",
        "    recall = metrics.recall_score(actual_label, predicted_label,pos_label=1)\n",
        "    AUROC = metrics.roc_auc_score(actual_label, predicted_label)\n",
        "    accuracy = metrics.accuracy_score(actual_label, predicted_label)\n",
        "    f1_score = metrics.f1_score(actual_label, predicted_label,pos_label=1)\n",
        "    return [f1_score, accuracy, precision, recall, AUROC]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "class decisionTreeClassifier:\n",
        "    def __init__(self, criterion: str = 'C4.5'):\n",
        "        self.__criterion = criterion\n",
        "        self.tree = None\n",
        "        self.data = None\n",
        "        self.predicted_labels = None\n",
        "        \n",
        "    def built_decision_tree(self, train_values : pd.DataFrame, train_features : pd.DataFrame, parent_data : pd.DataFrame):\n",
        "        '''Recursive function to build the decision tree.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        train_values : pd.DataFrame\n",
        "            Filtered training dataset from parent data to predict the value. The values in train_values and parent_data will be the same in the first iteration\n",
        "        train_features : pd.DataFrame\n",
        "            List of columns in the training dataset\n",
        "        parent_data : pd.DataFrame\n",
        "            Subset of training data set from previous iteration. In the first iteration it will be entire training data set\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        tree : dict\n",
        "            Decision tree that will used to predict\n",
        "        '''\n",
        "        tree = {}\n",
        "        helper = decisionTreeHelper(self.__criterion)\n",
        "        groupedbylabel = train_values.groupby('label')\n",
        "        class_categories = groupedbylabel['label'].unique()\n",
        "        if len(train_values) == 0:\n",
        "            return parent_data['label'].value_counts().index[0]\n",
        "        elif len(class_categories) == 1:\n",
        "            return class_categories[0][0]\n",
        "        elif len(list(train_features)) == 1:\n",
        "            return parent_data['label'].value_counts().index[0]\n",
        "        else:\n",
        "            best_split_value, best_feature = helper.get_best_feature(train_values, train_features)\n",
        "\n",
        "        if best_feature not in tree:\n",
        "            tree[best_feature] = {}\n",
        "        if best_feature not in feature_mapping['continuous']:\n",
        "          index_of_feature = list(train_features).index(best_feature)\n",
        "          unique_values = self.data[best_feature].unique()\n",
        "          unique_values.sort()\n",
        "          for values in unique_values:\n",
        "            train_values_filter = train_values.query(f\"{best_feature} == '{values}'\")\n",
        "            subtree = self.built_decision_tree(train_values_filter, list(train_features)[:index_of_feature]+list(train_features)[index_of_feature+1:] ,train_values)\n",
        "            tree[best_feature][values] = subtree\n",
        "        else:\n",
        "            for condition in ['<=','>']:\n",
        "              index_of_feature = list(train_features).index(best_feature)\n",
        "              train_values_filter = train_values.query(f'{best_feature} {condition} {best_split_value[best_feature]}')\n",
        "              subtree = self.built_decision_tree(train_values_filter, list(train_features)[:index_of_feature]+list(train_features)[index_of_feature+1:] ,train_values)\n",
        "              tree[best_feature][str(condition)+str(best_split_value[best_feature])] = subtree\n",
        "        return tree\n",
        "    \n",
        "    def fit(self, train_data : pd.DataFrame, train_label : pd.DataFrame):\n",
        "        '''Fit function to train the model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        train_data : pd.DataFrame\n",
        "            Training dataset\n",
        "        train_label : pd.DataFrame\n",
        "            List of columns in the training dataset\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        self.tree : dict\n",
        "            Decision tree that will used to predict\n",
        "        '''\n",
        "        helper = decisionTreeHelper(self.__criterion)\n",
        "        self.data = helper.merge_data_label(train_data, train_label)\n",
        "        self.train_label = train_label\n",
        "        self.tree = self.built_decision_tree(self.data, self.data.columns, self.data)\n",
        "        return self.tree\n",
        "    \n",
        "    def predict(self, test_data : pd.DataFrame):\n",
        "        '''Predict function to predict class label from trained model.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        test_data : pd.DataFrame\n",
        "            Test dataset with the class label column\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        predicted_labels : list\n",
        "            List of predicted labels\n",
        "        '''\n",
        "        self.predicted_labels = []\n",
        "        if isinstance(test_data, pd.DataFrame):\n",
        "            test_data = test_data.to_dict(orient='index')\n",
        "        for key in test_data.keys():\n",
        "            test_row = test_data[key]\n",
        "            predicted_labels = self.predict_each_label(self.tree, test_row)\n",
        "        return predicted_labels\n",
        "    \n",
        "    def predict_each_label(self, tree, test_row):\n",
        "        '''Recursive function to predict class label of each row in test dataset.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        tree : dict\n",
        "            Decision tree generated from fit function\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        self.predicted_labels : list\n",
        "            List of predicted labels\n",
        "        '''\n",
        "        columnName = list(tree.keys())[0]\n",
        "        decisionNodes = tree[columnName]\n",
        "        if columnName in feature_mapping['continuous']:\n",
        "            for values in list(decisionNodes):\n",
        "                if(eval(str(test_row.get(columnName))+str(values))):\n",
        "                    valValue = values\n",
        "                    if type(decisionNodes[valValue]) is not dict:\n",
        "                        predicted = decisionNodes[valValue]\n",
        "                        self.predicted_labels.append(predicted)\n",
        "                        return self.predicted_labels\n",
        "                    else:\n",
        "                        self.predict_each_label(decisionNodes[valValue], test_row)                     \n",
        "        else:\n",
        "            valValue = test_row.get(columnName)\n",
        "            if valValue in list(decisionNodes.keys()):\n",
        "                valValue = valValue\n",
        "            else:\n",
        "                valValue = random.choice(list(decisionNodes.keys()))\n",
        "            if type(decisionNodes[valValue]) is not dict:\n",
        "                predicted = decisionNodes[valValue]\n",
        "                self.predicted_labels.append(predicted)\n",
        "                return self.predicted_labels\n",
        "            else:\n",
        "                self.predict_each_label(decisionNodes[valValue], test_row)\n",
        "        return self.predicted_labels\n",
        "        \n",
        "    def cross_val_score(self, train_data : pd.DataFrame, splits : int = 10, shuffle : bool = False):\n",
        "        '''Function to perform cross validation.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        train_data : pd.DataFrame\n",
        "            Training dataset\n",
        "        splits : int, default = 10\n",
        "            Number split the train data\n",
        "        shuffle : bool, default = False\n",
        "            To randomize the split. Setting the shuffle argument to False will not randomize the split\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        kfold_index : Dict\n",
        "            Dictionary of each split indexes\n",
        "        performance_scores\n",
        "            Dictionary of performance metrics of each split\n",
        "        '''\n",
        "        helper = decisionTreeHelper(self.__criterion)\n",
        "        kfold_split = KFold(n_splits = splits, shuffle = shuffle)\n",
        "        performance_scores = {}\n",
        "        kfold_index = {}\n",
        "        for fold_index, (train_index, test_index) in enumerate(kfold_split.split(train_data)):\n",
        "            train_set = train_data.iloc[train_index]\n",
        "            train_label = train_set[feature_mapping['target']]\n",
        "            train_set= train_set.drop([feature_mapping['target']],axis=1)\n",
        "            self.fit(train_set, train_label)\n",
        "            dev_set = train_data.iloc[test_index]\n",
        "            actual_label = dev_set[feature_mapping['target']]\n",
        "            dev_set = dev_set.drop([feature_mapping['target']],axis=1)\n",
        "            predicted_label = self.predict(dev_set)\n",
        "            performance_scores[fold_index] = helper.get_performance_score(actual_label, predicted_label)\n",
        "            kfold_index[fold_index] = [train_index, test_index]\n",
        "        return kfold_index, performance_scores\n",
        "        \n",
        "    def best_estimator(self, kfold_index, performance_scores, train_data):\n",
        "        '''Function to train the model with best split from cross validation.\n",
        "        \n",
        "        Parameters\n",
        "        ----------\n",
        "        kfold_index : Dict\n",
        "            Dictionary of each split indexes\n",
        "        performance_scores\n",
        "            Dictionary of performance metrics of each split\n",
        "        train_data : pd.DataFrame\n",
        "            Training dataset\n",
        "        \n",
        "        Return\n",
        "        ------\n",
        "        self.tree : dict\n",
        "            Decision tree that will used to predict\n",
        "        '''\n",
        "        f1_score = []\n",
        "        performance_metrics = pd.DataFrame(performance_scores).T\n",
        "        performance_metrics = performance_metrics.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall',4:'AUROC'})\n",
        "        best_f1_index= np.argmax(performance_metrics['F1'])\n",
        "        for key, value in kfold_index.items():\n",
        "            if key == best_f1_index:\n",
        "                train_index, _ = kfold_index[key]\n",
        "                break  \n",
        "        train_set = train_data.iloc[train_index]\n",
        "        train_label = train_set[feature_mapping['target']]\n",
        "        train_set= train_set.drop([feature_mapping['target']],axis=1)\n",
        "        tree = self.fit(train_set, train_label)\n",
        "        return tree    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**main class to train and test decision tree using ID3, C4.5 and CART criterion**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [],
      "source": [
        "class main:\n",
        "    def id3(self, criterion):\n",
        "        id3_dto = decisionTreeClassifier(criterion)\n",
        "        helper_dto = decisionTreeHelper(criterion)\n",
        "        kfold_index, performance_scores = id3_dto.cross_val_score(train_data)\n",
        "        cross_val_score = pd.DataFrame(performance_scores).T\n",
        "        cross_val_score= cross_val_score.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall',4:'AUROC'})\n",
        "        id3_dt = id3_dto.best_estimator(kfold_index, performance_scores, train_data)\n",
        "        test_set = test_data\n",
        "        test_set = test_set.drop(feature_mapping['target'],axis = 1)\n",
        "        actual_label = test_data[feature_mapping['target']]\n",
        "        predicted_label = id3_dto.predict(test_set)\n",
        "        final_performance_metrics = helper_dto.get_performance_score(actual_label, predicted_label)\n",
        "        final_performance_metrics = pd.DataFrame(final_performance_metrics).T\n",
        "        final_performance_metrics.insert(0,'Criterion','ID3')\n",
        "        final_performance_metrics = final_performance_metrics.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall',4:'AUROC'})\n",
        "        return cross_val_score, final_performance_metrics, id3_dt\n",
        "    \n",
        "    def c45(self, criterion):\n",
        "        criterion='C4.5'\n",
        "        c45_dto = decisionTreeClassifier(criterion)\n",
        "        helper_dto = decisionTreeHelper(criterion)\n",
        "        kfold_index, performance_scores = c45_dto.cross_val_score(train_data)\n",
        "        cross_val_score = pd.DataFrame(performance_scores).T\n",
        "        cross_val_score= cross_val_score.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall',4:'AUROC'})\n",
        "        c45_dt = c45_dto.best_estimator(kfold_index, performance_scores, train_data)\n",
        "        test_set = test_data\n",
        "        test_set = test_set.drop(feature_mapping['target'],axis = 1)\n",
        "        actual_label = test_data[feature_mapping['target']]\n",
        "        predicted_label = c45_dto.predict(test_set)\n",
        "        final_performance_metrics = helper_dto.get_performance_score(actual_label, predicted_label)\n",
        "        final_performance_metrics = pd.DataFrame(final_performance_metrics).T\n",
        "        final_performance_metrics.insert(0,'Criterion',criterion)\n",
        "        final_performance_metrics = final_performance_metrics.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall',4:'AUROC'})\n",
        "        return cross_val_score, final_performance_metrics, c45_dt\n",
        "    \n",
        "    def cart(self, criterion):\n",
        "        criterion='CART'\n",
        "        cart_dto = decisionTreeClassifier(criterion)\n",
        "        helper_dto = decisionTreeHelper(criterion)\n",
        "        kfold_index, performance_scores = cart_dto.cross_val_score(train_data)\n",
        "        cross_val_score = pd.DataFrame(performance_scores).T\n",
        "        cross_val_score= cross_val_score.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall',4:'AUROC'})\n",
        "        cart_tree = cart_dto.best_estimator(kfold_index, performance_scores, train_data)\n",
        "        test_set = test_data\n",
        "        test_set = test_set.drop(feature_mapping['target'],axis = 1)\n",
        "        actual_label = test_data[feature_mapping['target']]\n",
        "        predicted_label = cart_dto.predict(test_set)\n",
        "        final_performance_metrics = helper_dto.get_performance_score(actual_label, predicted_label)\n",
        "        final_performance_metrics = pd.DataFrame(final_performance_metrics).T\n",
        "        final_performance_metrics.insert(0,'Criterion',criterion)\n",
        "        final_performance_metrics = final_performance_metrics.rename(columns={0:'F1',1:'Accuracy',2:'Precision',3:'Recall',4:'AUROC'})\n",
        "        return cross_val_score, final_performance_metrics, cart_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Object is created to train and test the decision using ID3, C4.5 and CART criterion\n",
        "main_obj = main()\n",
        "id3_cross_val_score, id3_final_score, id3_tree = main_obj.id3('ID3')\n",
        "c45_cross_val_score, c45_final_score, c45_tree = main_obj.c45('C4.5')\n",
        "cart_cross_val_score, cart_final_score, cart_tree = main_obj.cart('CART')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance metrics of all 10 splits from cross validation performed using ID3 criterion\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>AUROC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.737</td>\n",
              "      <td>0.818</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.920</td>\n",
              "      <td>0.927</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.920</td>\n",
              "      <td>0.927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.640</td>\n",
              "      <td>0.673</td>\n",
              "      <td>0.593</td>\n",
              "      <td>0.696</td>\n",
              "      <td>0.676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.750</td>\n",
              "      <td>0.782</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.783</td>\n",
              "      <td>0.782</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.683</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.875</td>\n",
              "      <td>0.560</td>\n",
              "      <td>0.747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.833</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.870</td>\n",
              "      <td>0.857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.741</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.745</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.791</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.944</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.706</td>\n",
              "      <td>0.727</td>\n",
              "      <td>0.818</td>\n",
              "      <td>0.621</td>\n",
              "      <td>0.733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.750</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.808</td>\n",
              "      <td>0.749</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      F1  Accuracy  Precision  Recall  AUROC\n",
              "0  0.737     0.818      0.700   0.778  0.808\n",
              "1  0.920     0.927      0.920   0.920  0.927\n",
              "2  0.640     0.673      0.593   0.696  0.676\n",
              "3  0.750     0.782      0.720   0.783  0.782\n",
              "4  0.683     0.764      0.875   0.560  0.747\n",
              "5  0.833     0.855      0.800   0.870  0.857\n",
              "6  0.741     0.745      0.741   0.741  0.745\n",
              "7  0.791     0.836      0.944   0.680  0.823\n",
              "8  0.706     0.727      0.818   0.621  0.733\n",
              "9  0.750     0.745      0.700   0.808  0.749"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f'Performance metrics of all 10 splits from cross validation performed using ID3 criterion')\n",
        "id3_cross_val_score.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID3 final performance metrics based on prediction made from test set \n",
            " Best split from cross validation is used to train and test the model on test dataset\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Criterion</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>AUROC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ID3</td>\n",
              "      <td>0.806</td>\n",
              "      <td>0.821</td>\n",
              "      <td>0.788</td>\n",
              "      <td>0.825</td>\n",
              "      <td>0.822</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Criterion     F1  Accuracy  Precision  Recall  AUROC\n",
              "0       ID3  0.806     0.821      0.788   0.825  0.822"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f'ID3 final performance metrics based on prediction made from test set \\n Best split from cross validation is used to train and test the model on test dataset')\n",
        "id3_final_score.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance metrics of all 10 splits from cross validation performed using C4.5 criterion\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>AUROC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.769</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.846</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.880</td>\n",
              "      <td>0.857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.840</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.913</td>\n",
              "      <td>0.863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.870</td>\n",
              "      <td>0.891</td>\n",
              "      <td>0.870</td>\n",
              "      <td>0.870</td>\n",
              "      <td>0.888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.698</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.833</td>\n",
              "      <td>0.600</td>\n",
              "      <td>0.750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.846</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.759</td>\n",
              "      <td>0.957</td>\n",
              "      <td>0.869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.800</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.786</td>\n",
              "      <td>0.815</td>\n",
              "      <td>0.800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.818</td>\n",
              "      <td>0.855</td>\n",
              "      <td>0.947</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.836</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.793</td>\n",
              "      <td>0.839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.786</td>\n",
              "      <td>0.782</td>\n",
              "      <td>0.733</td>\n",
              "      <td>0.846</td>\n",
              "      <td>0.785</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      F1  Accuracy  Precision  Recall  AUROC\n",
              "0  0.769     0.836      0.714   0.833  0.836\n",
              "1  0.846     0.855      0.815   0.880  0.857\n",
              "2  0.840     0.855      0.778   0.913  0.863\n",
              "3  0.870     0.891      0.870   0.870  0.888\n",
              "4  0.698     0.764      0.833   0.600  0.750\n",
              "5  0.846     0.855      0.759   0.957  0.869\n",
              "6  0.800     0.800      0.786   0.815  0.800\n",
              "7  0.818     0.855      0.947   0.720  0.843\n",
              "8  0.836     0.836      0.885   0.793  0.839\n",
              "9  0.786     0.782      0.733   0.846  0.785"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f'Performance metrics of all 10 splits from cross validation performed using C4.5 criterion')\n",
        "c45_cross_val_score.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C4.5 final performance metrics based on prediction made from test set \n",
            " Best split from cross validation is used to train and test the model on test dataset\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Criterion</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>AUROC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C4.5</td>\n",
              "      <td>0.8</td>\n",
              "      <td>0.821</td>\n",
              "      <td>0.806</td>\n",
              "      <td>0.794</td>\n",
              "      <td>0.819</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Criterion   F1  Accuracy  Precision  Recall  AUROC\n",
              "0      C4.5  0.8     0.821      0.806   0.794  0.819"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f'C4.5 final performance metrics based on prediction made from test set \\n Best split from cross validation is used to train and test the model on test dataset')\n",
        "c45_final_score.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Performance metrics of all 10 splits from cross validation performed using CART criterion\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>AUROC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.737</td>\n",
              "      <td>0.818</td>\n",
              "      <td>0.700</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.739</td>\n",
              "      <td>0.782</td>\n",
              "      <td>0.810</td>\n",
              "      <td>0.680</td>\n",
              "      <td>0.773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.766</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.783</td>\n",
              "      <td>0.798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.698</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.750</td>\n",
              "      <td>0.652</td>\n",
              "      <td>0.748</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.809</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.864</td>\n",
              "      <td>0.760</td>\n",
              "      <td>0.830</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.784</td>\n",
              "      <td>0.800</td>\n",
              "      <td>0.714</td>\n",
              "      <td>0.870</td>\n",
              "      <td>0.810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.755</td>\n",
              "      <td>0.764</td>\n",
              "      <td>0.769</td>\n",
              "      <td>0.741</td>\n",
              "      <td>0.763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.800</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.900</td>\n",
              "      <td>0.720</td>\n",
              "      <td>0.827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.720</td>\n",
              "      <td>0.745</td>\n",
              "      <td>0.857</td>\n",
              "      <td>0.621</td>\n",
              "      <td>0.753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.704</td>\n",
              "      <td>0.709</td>\n",
              "      <td>0.679</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      F1  Accuracy  Precision  Recall  AUROC\n",
              "0  0.737     0.818      0.700   0.778  0.808\n",
              "1  0.739     0.782      0.810   0.680  0.773\n",
              "2  0.766     0.800      0.750   0.783  0.798\n",
              "3  0.698     0.764      0.750   0.652  0.748\n",
              "4  0.809     0.836      0.864   0.760  0.830\n",
              "5  0.784     0.800      0.714   0.870  0.810\n",
              "6  0.755     0.764      0.769   0.741  0.763\n",
              "7  0.800     0.836      0.900   0.720  0.827\n",
              "8  0.720     0.745      0.857   0.621  0.753\n",
              "9  0.704     0.709      0.679   0.731  0.710"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f'Performance metrics of all 10 splits from cross validation performed using CART criterion')\n",
        "cart_cross_val_score.round(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CART final performance metrics based on prediction made from test set \n",
            " Best split from cross validation is used to train and test the model on test dataset\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Criterion</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>AUROC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CART</td>\n",
              "      <td>0.784</td>\n",
              "      <td>0.807</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.804</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Criterion     F1  Accuracy  Precision  Recall  AUROC\n",
              "0      CART  0.784     0.807       0.79   0.778  0.804"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f'CART final performance metrics based on prediction made from test set \\n Best split from cross validation is used to train and test the model on test dataset')\n",
        "cart_final_score.round(3)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
